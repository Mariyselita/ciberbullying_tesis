{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ni8tlvuARph"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU0CfGwdqh2a",
        "outputId": "b283f6ea-0d69-40af-fd44-b26d6f3dd040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/dataset/cyberbullying_tweets.csv'"
      ],
      "metadata": {
        "id": "APOT-ayEuV6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "hZebNysfujLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnDLbDgswIP1",
        "outputId": "714f789b-bce7-495a-80fc-a35c53b94c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          tweet_text cyberbullying_type\n",
            "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
            "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
            "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
            "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
            "4  If you are feeling perturbed about women that ...  not_cyberbullying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frkS7mHUwnoN",
        "outputId": "bea807e0-0176-4cc8-92b7-a7ca3922e62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet_text            0\n",
            "cyberbullying_type    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset[\"tweet_text\"]  # Características\n",
        "y = dataset[\"cyberbullying_type\"]  # Etiquetas"
      ],
      "metadata": {
        "id": "65TSBC-iwpYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TLN\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjC3aKTOx-Pv",
        "outputId": "7e4f69bf-a53b-4139-9c78-36b2742bcc13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenización\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "UqPBQqwJ0t13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminación de stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    return filtered_tokens"
      ],
      "metadata": {
        "id": "cVRv6o0j1AsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento\n",
        "def preprocess_text(text):\n",
        "    tokens = tokenize_text(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "Iil2fVCQ1Iko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento a todas las características\n",
        "X_preprocessed = X.apply(preprocess_text)"
      ],
      "metadata": {
        "id": "W5F4My8C2jQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X_preprocessed)"
      ],
      "metadata": {
        "id": "3Z7kMmiW3BIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz TF-IDF resultante\n",
        "print(\"Matriz TF-IDF:\", X_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viNHNyrW3iDe",
        "outputId": "9a528b21-72b3-45b8-ef82-fe7500b5844a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz TF-IDF: (46976, 59652)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "5lgBbnSX5uzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjuntos de entrenamiento (80%) y prueba (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "azL8HlOs5zJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return {'label': max(set(y), key=list(y).count)}  # Devuelve la clase mayoritaria en caso de alcanzar la profundidad max\n",
        "        if len(np.unique(y)) == 1:\n",
        "            return {'label': y[0]}\n",
        "\n",
        "        best_split = self._find_best_split(X, y)\n",
        "        if best_split is None:\n",
        "            return {'label': max(set(y), key=list(y).count)}  # Devuelve la clase mayoritaria si no hay división posible\n",
        "\n",
        "        left_idxs = X[:, best_split['feature']] < best_split['threshold']\n",
        "        right_idxs = ~left_idxs\n",
        "\n",
        "        if np.sum(left_idxs) == 0 or np.sum(right_idxs) == 0:\n",
        "            return {'label': max(set(y), key=list(y).count)}\n",
        "\n",
        "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
        "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
        "\n",
        "        return {'feature': best_split['feature'],\n",
        "                'threshold': best_split['threshold'],\n",
        "                'left': left_subtree,\n",
        "                'right': right_subtree}\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_gini = 1.0\n",
        "        best_split = None\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        for feature in range(n_features):\n",
        "            thresholds = np.percentile(X[:, feature], [10, 25, 50, 75, 90])\n",
        "            for threshold in thresholds:\n",
        "                left_idxs = X[:, feature] < threshold\n",
        "                if np.sum(left_idxs) == 0 or np.sum(left_idxs) == len(y):\n",
        "                    continue\n",
        "                gini = self._gini_impurity(y[left_idxs]) * np.mean(left_idxs) + \\\n",
        "                       self._gini_impurity(y[~left_idxs]) * np.mean(~left_idxs)\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_split = {'feature': feature, 'threshold': threshold}\n",
        "        return best_split\n",
        "\n",
        "    def _gini_impurity(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        class_probs = np.array([np.mean(y == c) for c in np.unique(y)])\n",
        "        return 1 - np.sum(class_probs ** 2)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_tree(x, self.tree) if self.tree is not None else None for x in X])\n",
        "\n",
        "    def _predict_tree(self, x, tree):\n",
        "        if tree is None:\n",
        "            return None\n",
        "        if 'label' in tree:\n",
        "            return tree['label']\n",
        "        if x[tree['feature']] < tree['threshold']:\n",
        "            return self._predict_tree(x, tree['left'])\n",
        "        else:\n",
        "            return self._predict_tree(x, tree['right'])\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "tree = DecisionTree(max_depth=2)\n",
        "tree.fit(X_train_dense, y_train)\n",
        "y_pred = tree.predict(X_test_dense)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo:\", accuracy)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTo2XAtjmmLp",
        "outputId": "af309c62-11f2-49b2-bcca-0def5f9e10cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.3468497232865049\n",
            "Reporte de clasificación:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                age       0.97      0.52      0.68      1572\n",
            "          ethnicity       0.97      0.59      0.73      1545\n",
            "             gender       0.20      0.99      0.34      1552\n",
            "  not_cyberbullying       0.00      0.00      0.00      1564\n",
            "other_cyberbullying       0.00      0.00      0.00      1553\n",
            "           religion       0.00      0.00      0.00      1610\n",
            "\n",
            "           accuracy                           0.35      9396\n",
            "          macro avg       0.36      0.35      0.29      9396\n",
            "       weighted avg       0.36      0.35      0.29      9396\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}